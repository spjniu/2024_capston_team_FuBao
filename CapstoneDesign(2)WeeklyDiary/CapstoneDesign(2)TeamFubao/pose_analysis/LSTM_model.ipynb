{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 미디어파이프 초기화\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.5)\n",
    "\n",
    "# 데이터 저장 리스트\n",
    "pose_data = []\n",
    "labels = []\n",
    "\n",
    "# 폴더 경로 설정 (올바른 자세는 1, 틀린 자세는 0)\n",
    "base_folders = {\n",
    "    \"right_position\": 1,  # 올바른 자세\n",
    "    \"wrong_position\": 0   # 틀린 자세\n",
    "}\n",
    "\n",
    "# 각 폴더의 데이터 전처리\n",
    "for folder_name, label in base_folders.items():\n",
    "    base_folder = f\"C:/Users/spjni/vscode/2024-2capstone/{folder_name}\"  # 각 폴더의 경로 설정\n",
    "    for subfolder_name in os.listdir(base_folder):\n",
    "        folder_path = os.path.join(base_folder, subfolder_name)\n",
    "        if not os.path.isdir(folder_path):  # 폴더가 아닌 파일은 제외\n",
    "            continue\n",
    "        \n",
    "        # 각 하위 폴더 안의 이미지 파일 처리\n",
    "        for i in range(1, 33):  # 각 세트의 32 프레임\n",
    "            file_name = os.path.join(folder_path, f\"{subfolder_name}-{i:07d}.jpg\")  # 이미지 파일 경로\n",
    "            image = cv2.imread(file_name)\n",
    "            if image is None:\n",
    "                continue\n",
    "            \n",
    "            # 미디어파이프를 이용한 키포인트 추출\n",
    "            results = pose.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "            if results.pose_landmarks:\n",
    "                # x, y 좌표 추출\n",
    "                keypoints = [landmark.x for landmark in results.pose_landmarks.landmark] + \\\n",
    "                            [landmark.y for landmark in results.pose_landmarks.landmark]\n",
    "                pose_data.append([subfolder_name, i] + keypoints)\n",
    "                labels.append(label)  # 해당 데이터의 라벨 추가\n",
    "\n",
    "# 데이터프레임 생성 및 CSV 저장\n",
    "columns = [\"set_id\", \"frame_id\"] + [f\"x_{i}\" for i in range(33)] + [f\"y_{i}\" for i in range(33)]\n",
    "df = pd.DataFrame(pose_data, columns=columns)\n",
    "df['label'] = labels  # 라벨 컬럼 추가\n",
    "df.to_csv(\"overhead_press_joint_positions_with_labels.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (414, 64, 66)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# CSV 파일 로드 (첫 번째 코드에서 저장한 CSV 파일)\n",
    "file_path = \"overhead_press_joint_positions_with_labels.csv\"\n",
    "joint_positions = pd.read_csv(file_path)\n",
    "\n",
    "# 시퀀스 데이터 구성 및 길이 고정\n",
    "sequences = []\n",
    "labels = []\n",
    "\n",
    "for set_id in joint_positions['set_id'].unique():\n",
    "    # 각 set_id에 해당하는 관절 좌표 시퀀스 추출\n",
    "    sequence = joint_positions[joint_positions[\"set_id\"] == set_id].iloc[:, 2:-1].values  # x, y 좌표만 추출\n",
    "    label = joint_positions[joint_positions[\"set_id\"] == set_id][\"label\"].iloc[0]  # 해당 set_id의 라벨 (0 또는 1)\n",
    "    \n",
    "    # 시퀀스 길이가 64보다 길 경우, 앞에서 64개 프레임만 추출\n",
    "    if sequence.shape[0] > 64:\n",
    "        sequence = sequence[:64]  # 64개 프레임만 사용\n",
    "    elif sequence.shape[0] < 64:\n",
    "        sequence = pad_sequences([sequence], maxlen=64, dtype='float32', padding='post', truncating='post')[0]\n",
    "\n",
    "    sequences.append(sequence)\n",
    "    labels.append(label)\n",
    "\n",
    "# 시퀀스를 numpy 배열로 변환 (64 프레임, 66 좌표로 고정)\n",
    "X_train = np.array(sequences)\n",
    "y_train = np.array(labels)\n",
    "\n",
    "# 데이터의 형태 확인\n",
    "print(\"Training data shape:\", X_train.shape)  # (n_samples, 64 프레임, 66 좌표)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 64)                33536     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 35,649\n",
      "Trainable params: 35,649\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 8s 43ms/step - loss: 0.6278 - accuracy: 0.9668 - val_loss: 0.4929 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.2737 - accuracy: 0.9668 - val_loss: 0.0468 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.1488 - accuracy: 0.9668 - val_loss: 0.0168 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.1488 - accuracy: 0.9668 - val_loss: 0.0355 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.1449 - accuracy: 0.9668 - val_loss: 0.0386 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.1451 - accuracy: 0.9668 - val_loss: 0.0311 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.1444 - accuracy: 0.9668 - val_loss: 0.0338 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.1442 - accuracy: 0.9668 - val_loss: 0.0363 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.1439 - accuracy: 0.9668 - val_loss: 0.0344 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.1443 - accuracy: 0.9668 - val_loss: 0.0314 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "import numpy as np\n",
    "\n",
    "# LSTM 모델 정의\n",
    "model = Sequential([\n",
    "    LSTM(64, activation='tanh', recurrent_activation='sigmoid', input_shape=(64, 66), return_sequences=False),  # 입력 크기 (64, 66)\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # 이진 분류 (0 또는 1)\n",
    "])\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 모델 요약\n",
    "model.summary()\n",
    "\n",
    "# 모델 훈련\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n",
    "# 모델 저장 (H5 형식으로 저장)\n",
    "model.save('overhead_press_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (414, 64, 66)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# CSV 파일 로드 (첫 번째 코드에서 저장한 CSV 파일)\n",
    "file_path = \"overhead_press_joint_positions_with_labels.csv\"\n",
    "joint_positions = pd.read_csv(file_path)\n",
    "\n",
    "# 시퀀스 데이터 구성 및 길이 고정\n",
    "sequences = []\n",
    "labels = []\n",
    "\n",
    "for set_id in joint_positions['set_id'].unique():\n",
    "    # 각 set_id에 해당하는 관절 좌표 시퀀스 추출\n",
    "    sequence = joint_positions[joint_positions[\"set_id\"] == set_id].iloc[:, 2:-1].values  # x, y 좌표만 추출\n",
    "    label = joint_positions[joint_positions[\"set_id\"] == set_id][\"label\"].iloc[0]  # 해당 set_id의 라벨 (0 또는 1)\n",
    "    \n",
    "    # 시퀀스 길이가 64보다 길 경우, 앞에서 64개 프레임만 추출\n",
    "    if sequence.shape[0] > 64:\n",
    "        sequence = sequence[:64]  # 64개 프레임만 사용\n",
    "    elif sequence.shape[0] < 64:\n",
    "        sequence = pad_sequences([sequence], maxlen=64, dtype='float32', padding='post', truncating='post')[0]\n",
    "\n",
    "    sequences.append(sequence)\n",
    "    labels.append(label)\n",
    "\n",
    "# 시퀀스를 numpy 배열로 변환 (64 프레임, 66 좌표로 고정)\n",
    "X_train = np.array(sequences)\n",
    "y_train = np.array(labels)\n",
    "\n",
    "# 데이터의 형태 확인\n",
    "print(\"Training data shape:\", X_train.shape)  # (n_samples, 64 프레임, 66 좌표)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
